# -*- coding: utf-8 -*-
"""train_functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14JFEqyy8EwtDysFFcTmcH0fncX2sem1A
"""

from datasets import load_dataset
from torch.utils.data import DataLoader, random_split, Dataset
import torch.nn as nn
import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import json, os

def accuracy(output, target):
  # (batch_size,1)
  batch_size = target.size(0)
  output_th = (output[:,0].view(-1,1) > 0.5).float()
  correct = output_th.eq(target).sum().item()
  return correct / batch_size

def show_tenosr_image(tensor_image):
  # PyTorch tensors assume the color channel is the first dimension
  # but matplotlib assumes is the third dimension
  # tensor_image.shape = (C, H, W)
  tensor_image = torch.transpose(tensor_image,0,2)
  tensor_image = torch.transpose(tensor_image,0,1)
  arr_ = np.squeeze(tensor_image)
  plt.imshow(arr_)
  plt.show()

def plot_loss_acc(test_loss,train_loss,test_acc,model_name):
  x = list(range(len(test_loss)))
  fig,ax = plt.subplots(1,2,figsize=(10,5))
  ax[0].plot(x,test_loss,marker='o',label='test_loss')
  ax[0].plot(x,train_loss,marker='o',color='green',label='train_loss')
  ax[0].set_xlabel('Epochs')
  ax[0].set_ylabel('Loss')
  ax[0].grid(True)
  ax[0].legend()
  ax[0].set_title(model_name)
  #plt.show()
  #fig.savefig(model_name+'_loss.png')

  #fig2,ax2 = plt.subplots(1,1,figsize=(10,5))
  ax[1].plot(x,test_acc,marker='o',label='test_acc',color='magenta')
  ax[1].set_xlabel('Epochs')
  ax[1].set_ylabel('Accuracy')
  ax[1].grid(True)
  ax[1].legend()
  ax[1].set_title(model_name)
  plt.show()
  #fig.savefig(model_name+'_acc.png')
  fig.savefig(model_name+'_loss_acc.png')

def adversarial_training(model, images, labels, criterion, epsilon=0.01):
  '''
  model: neural network model
  images: (batch_size,C,H,W)
  labels: (batch_size,1)
  criterion: loss function, should be NLL
  epsilon: epsilon for adversarial training

  call this function between optimizer.zero_grad() and optimizer.step()
  returns the total loss
  '''
  images.requires_grad = True

  #images_copy = images.clone().detach()
  #show_tenosr_image(images_copy[0])

  outputs = model(images)
  #print('outputs:',outputs)
  #print('labels:',labels)
  loss = criterion(outputs, labels)
  loss.backward(retain_graph=True)
  grad = images.grad.data # gradients wrt input
  adversarial_examples = images + epsilon * torch.sign(grad)

  #show_tenosr_image(epsilon * torch.sign(grad)[0])

  #print(epsilon * torch.sign(grad)[0])

  #adversarial_examples_copy = adversarial_examples.clone().detach()
  #show_tenosr_image(adversarial_examples_copy[0])

  model.zero_grad()


  outputs_adv = model(adversarial_examples)

  #print('outputs_adv:',outputs_adv)

  loss_adv = criterion(outputs_adv, labels)
  loss_total = loss + loss_adv
  loss_total.backward()
  return loss_total


def negative_log_likelihood(output, target):
  '''
  output: (batch_size,2)
  target: (batch_size,1)
  '''

  loss_fn = nn.GaussianNLLLoss()
  loss = loss_fn(input=output[:,0:1], target=target, var=output[:,1:2])
  return loss
  '''
  batch_size = target.size(0)
  t1 = (0.5 * torch.log(output[:,1].view(-1,1)))
  t2 = torch.div(torch.square(target - output[:,0].view(-1,1)), 2*output[:,1].view(-1,1) + 1e-6)
  total = (t1 + t2).sum() / batch_size
  return total
  '''

def test_model(model=None, testloader=None, device='cpu', criterion=nn.BCELoss()):
  model = model.to(device)
  #dataset_test = dataset_test_class(dataset.select(range(test_num)))
  #testloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)

  model.eval()
  test_loss = 0
  test_acc = 0
  var = torch.rand((1)).to(device)
  with torch.no_grad():
    for i, o in enumerate(testloader):
      batched_input = o['image']
      batched_input = batched_input.to(device)

      batched_target = o['label'].reshape(-1,1)
      batched_target = batched_target.to(device)
      output = model(batched_input)
      loss = criterion(output, batched_target)
      test_loss += loss.item()
      test_acc += accuracy(output, batched_target)
      if (output.shape[1]==2):
        var = torch.cat((var, output[:,1]))

  test_loss /= len(testloader) # average test loss of this epoch
  test_acc /= len(testloader) # average test accuracy of this epoch
  
  return test_loss, test_acc, var


def train_model(model=None, dataset_train=None, dataset_train_class=Dataset, dataset_test=None, dataset_test_class=Dataset, \
         learning_rate=1e-3, batch_size=32, step_size=1, epochs=1, output_rate=1, device='cpu', save_dir=None, save_model_name='test.pt', \
         train_num=5000, test_num=1000, adversarial=False, criterion=nn.BCELoss()):
  #dataset_train.set_format(type='torch', columns=['image', 'label']) # set the format of the image and label to tensor
  model = model.to(device)

  if (dataset_train_class and dataset_test_class):
    dataset_train = dataset_train_class(dataset_train.select(range(train_num)))
    dataset_test = dataset_test_class(dataset_test.select(range(test_num)))

    print(f'length of training set: {len(dataset_train)}')
    print(f'length of testing set: {len(dataset_test)}')

    train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)
    testloader = DataLoader(dataset_test, batch_size=batch_size, shuffle=False)

  else:
    sampler_train = torch.utils.data.RandomSampler(dataset_train, num_samples=train_num)
    train_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=sampler_train)

    print(f'length of training set: {train_num}')
    print(f'length of testing set: {test_num}')

    sampler_test = torch.utils.data.RandomSampler(dataset_test, num_samples=test_num)
    testloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, sampler=sampler_test)





  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)
  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.5)

  '''
  if not adversarial:
    criterion = nn.BCELoss()  # Binary Cross Entropy Loss
  else:
    criterion = negative_log_likelihood # if adversarial is True, the loss is NLL loss
  '''
  #criterion = criterion

  train_loss_arr = []
  test_loss_arr = []
  test_acc_arr = []
  best_acc = 0

  for epoch in tqdm(range(epochs)):
    model.train()
    train_loss = 0
    for i, o in enumerate(train_loader):
      batched_input = o['image']
      batched_input = batched_input.to(device)

      batched_target = o['label'].reshape(-1,1)
      batched_target = batched_target.to(device)

      optimizer.zero_grad()
      if not adversarial:
        output = model(batched_input)
        loss = criterion(output, batched_target)
        loss.backward()
      else:
        loss = adversarial_training(model, batched_input, batched_target, criterion)
      optimizer.step()
      train_loss += loss.item()

    train_loss /= len(train_loader) # average train loss of this epoch
    scheduler.step()

    model.eval()
    test_loss, test_acc, _ = test_model(model=model, testloader=testloader, device=device, criterion=criterion)
    '''
    model.eval()
    test_loss = 0
    test_acc = 0
    with torch.no_grad():
      for i, o in enumerate(testloader):
        batched_input = o['image']
        batched_input = batched_input.to(device)

        batched_target = o['label'].reshape(-1,1)
        batched_target = batched_target.to(device)
        output = model(batched_input)
        loss = criterion(output, batched_target)
        test_loss += loss.item()
        test_acc += accuracy(output, batched_target)

    test_loss /= len(testloader) # average test loss of this epoch
    test_acc /= len(testloader) # average test accuracy of this epoch
    '''

    #train_loss /= len(train_loader) # average train loss of this epoch
    if test_acc > best_acc:
      best_acc = test_acc
      if save_dir:
        torch.save(model.state_dict(), save_dir+save_model_name)
      else:
        torch.save(model.state_dict(), save_model_name)


    train_loss_arr.append(train_loss)
    test_loss_arr.append(test_loss)
    test_acc_arr.append(test_acc)

    if not os.path.exists(save_dir+save_model_name[:-3]):
      os.makedirs(save_dir+save_model_name[:-3])


    with open(save_dir+save_model_name[:-3]+'/train_loss.json', 'w') as f:
      json.dump(train_loss_arr, f)
    with open(save_dir+save_model_name[:-3]+'/test_loss.json', 'w') as f:
      json.dump(test_loss_arr, f)
    with open(save_dir+save_model_name[:-3]+'/test_acc.json', 'w') as f:
      json.dump(test_acc_arr, f)


    if epoch%output_rate == 0:
                print(f'epoch:{epoch}, current train loss:{train_loss_arr[-1]:5.3f},\t \
                      current test loss:{test_loss_arr[-1]:5.3f},\t \
                      best accuracy:{best_acc:5.3f}')

